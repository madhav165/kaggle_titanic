{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9864916a-38e1-4df4-a922-c888ff583848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7b8837-89c0-4b4d-a8ee-c032f0652673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa1a17-daac-44ca-a28c-d6815b3415ec",
   "metadata": {},
   "source": [
    "### Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af2ca32-3b1f-47d1-8f87-325252fab08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median_age = df_train.groupby(['Sex', 'Pclass'])['Age'].median().reset_index()\n",
    "df_median_age = df_median_age.rename(columns={'Age' : 'Median_Age'})\n",
    "\n",
    "df_train = df_train.merge(df_median_age, on=['Sex', 'Pclass'], how='left')\n",
    "df_train.loc[df_train['Age'].isna(), 'Age'] = df_train['Median_Age']\n",
    "df_train = df_train.drop(columns = 'Median_Age')\n",
    "\n",
    "df_test = df_test.merge(df_median_age, on=['Sex', 'Pclass'], how='left')\n",
    "df_test.loc[df_test['Age'].isna(), 'Age'] = df_test['Median_Age']\n",
    "df_test = df_test.drop(columns = 'Median_Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87ec30be-5e8f-4e35-b602-d2163ce223f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Cabin_Type'] = df_train.loc[df_train['Cabin'].notna()]['Cabin'].apply(lambda x: x[0])\n",
    "df_test['Cabin_Type'] = df_test.loc[df_test['Cabin'].notna()]['Cabin'].apply(lambda x: x[0])\n",
    "\n",
    "df_train['Cabin_Nos'] = df_train.loc[df_train['Cabin'].notna()]['Cabin'].apply(lambda x: len(x.split()))\n",
    "df_test['Cabin_Nos'] = df_test.loc[df_test['Cabin'].notna()]['Cabin'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_train = df_train.drop(columns='Cabin')\n",
    "df_test = df_test.drop(columns='Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "651e141e-4689-4985-95e5-d418178f9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.get_dummies(df_train['Sex'])\n",
    "df_train = pd.concat([df_train, new_df_train], axis=1)\n",
    "\n",
    "new_df_test = pd.get_dummies(df_test['Sex'])\n",
    "df_test = pd.concat([df_test, new_df_test], axis=1)\n",
    "\n",
    "df_train = df_train.drop(columns=['Sex'])\n",
    "df_test = df_test.drop(columns=['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8be9f04e-bd47-400c-a3d0-50227de9cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Embarked'] = df_train['Embarked'].fillna('S')\n",
    "df_test['Embarked'] = df_test['Embarked'].fillna('S')\n",
    "\n",
    "new_df_train = pd.get_dummies(df_train['Embarked'])\n",
    "new_cols = ['Embarked_{}'.format(x) for x in new_df_train.columns.values]\n",
    "new_df_train.columns = new_cols\n",
    "df_train = pd.concat([df_train, new_df_train], axis=1)\n",
    "\n",
    "new_df_test = pd.get_dummies(df_test['Embarked'])\n",
    "new_cols = ['Embarked_{}'.format(x) for x in new_df_test.columns.values]\n",
    "new_df_test.columns = new_cols\n",
    "df_test = pd.concat([df_test, new_df_test], axis=1)\n",
    "\n",
    "df_train = df_train.drop(columns=['Embarked'])\n",
    "df_test = df_test.drop(columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bf6d4b9-ca35-4af0-b113-91b07494944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.get_dummies(df_train['Cabin_Type'])\n",
    "new_cols = ['Cabin_Type_{}'.format(x) for x in new_df_train.columns.values]\n",
    "new_df_train.columns = new_cols\n",
    "df_train = pd.concat([df_train, new_df_train], axis=1)\n",
    "\n",
    "new_df_test = pd.get_dummies(df_test['Cabin_Type'])\n",
    "new_cols = ['Cabin_Type_{}'.format(x) for x in new_df_test.columns.values]\n",
    "new_df_test.columns = new_cols\n",
    "df_test = pd.concat([df_test, new_df_test], axis=1)\n",
    "\n",
    "df_train = df_train.drop(columns=['Cabin_Type'])\n",
    "df_test = df_test.drop(columns=['Cabin_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6daa7d34-f9b3-41ac-806a-dde513ae17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_fare_dict = df_train.groupby('Pclass')['Fare'].median().to_dict()\n",
    "\n",
    "df_train['Pclass_Fare_median'] = df_train['Pclass'].apply(lambda x: class_fare_dict[x])\n",
    "df_test['Pclass_Fare_median'] = df_test['Pclass'].apply(lambda x: class_fare_dict[x])\n",
    "\n",
    "df_train.loc[df_train['Fare'].isna(), 'Fare'] = df_train['Pclass_Fare_median']\n",
    "df_test.loc[df_test['Fare'].isna(), 'Fare'] = df_test['Pclass_Fare_median']\n",
    "\n",
    "df_train = df_train.drop(columns = 'Pclass_Fare_median')\n",
    "df_test = df_test.drop(columns = 'Pclass_Fare_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8da2347-837f-440f-ac91-aedd6e5928ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.get_dummies(df_train['Pclass'])\n",
    "new_cols = ['Pclass_{}'.format(x) for x in new_df_train.columns.values]\n",
    "new_df_train.columns = new_cols\n",
    "df_train = pd.concat([df_train, new_df_train], axis=1)\n",
    "\n",
    "new_df_test = pd.get_dummies(df_test['Pclass'])\n",
    "new_cols = ['Pclass_{}'.format(x) for x in new_df_test.columns.values]\n",
    "new_df_test.columns = new_cols\n",
    "df_test = pd.concat([df_test, new_df_test], axis=1)\n",
    "\n",
    "df_train = df_train.drop(columns=['Pclass'])\n",
    "df_test = df_test.drop(columns=['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "039e9185-78f3-4cce-bd65-498446ba37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Cabin_Nos'] = df_train['Cabin_Nos'].fillna(1)\n",
    "df_test['Cabin_Nos'] = df_test['Cabin_Nos'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b455a57-8586-4446-b3e3-aca59c81fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Cabin_Type_T'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2266bbcd-1247-4bd8-90d5-1d7499fefc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_col_list = list(df_train.columns.values)\n",
    "inp_col_list.remove('PassengerId')\n",
    "inp_col_list.remove('Survived')\n",
    "inp_col_list.remove('Name')\n",
    "inp_col_list.remove('Ticket')\n",
    "inp_col_list.remove('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22811efc-2827-4e1a-b16a-4a6d50d345ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[inp_col_list]\n",
    "Y = df_train['Survived']\n",
    "\n",
    "x = X.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "X_scaled = pd.DataFrame(x_scaled)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf791b8e-4dbb-4e13-96b6-4e36f8c8296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth = 6, min_samples_split = 5, random_state = 42)\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "984fefa6-10f9-4843-867c-01c23130acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "score = rfc.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c97534bb-59b3-49a7-a490-33162a59133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test[inp_col_list]\n",
    "x = X.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "X_scaled = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85962942-7c66-4297-a30d-cf08e1784a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ec899fc-8692-42d8-ad74-48e4f2972300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Survived'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c094fd5d-2b16-4edb-ade2-ccb4a7084a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['PassengerId', 'Survived']].to_csv('../submissions/random_forest_4_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8f534-414a-49b1-b193-82ecfd4582f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
